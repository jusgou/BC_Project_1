{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ROBOMYSTIC: Automated Investing that Feels Human"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Client Onboarding and Know Your Client Criteria\n",
    "##### Our company compiles customer data by having prospective clients fill out an intake form. Although our mock-up doesn't fulfill all the 'Know Your Client' (KYC) criteria as required by Canadian law, we have approximated to simulate how KYC data would be stored and imported into our automated system to pair clients with the appropriate portfolio. We have chosen the .YAML file format for its versatility and the ability it gives us to iterate through an (hopefully for our firm) ever-increasing number of client forms automatically. Future versions of our software would include identity verification technology, a more robust suitability criterion by which we might reject prospective clients based on, for example, creditworthiness or anti-money laundering grounds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'alpaca_trade_api'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-0eab4b76adb9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mholoviews\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mhv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0malpaca_trade_api\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtradeapi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mMCForecastTools\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMCSimulation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'alpaca_trade_api'"
     ]
    }
   ],
   "source": [
    "# Import Libraries and Modules\n",
    "import panel as pn\n",
    "pn.extension('plotly')\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "import hvplot.pandas\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import requests\n",
    "import urllib.request \n",
    "import os\n",
    "import json\n",
    "from pandas.io.json import json_normalize\n",
    "import seaborn as sns\n",
    "import yfinance as yf\n",
    "from yahoofinancials import YahooFinancials\n",
    "from datetime import date\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "from datetime import date\n",
    "from pandas_datareader import data as pdr\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import yaml\n",
    "import io\n",
    "import pytz\n",
    "import glob\n",
    "import holoviews as hv\n",
    "import alpaca_trade_api as tradeapi\n",
    "from MCForecastTools import MCSimulation\n",
    "\n",
    "yf.pdr_override()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load .env enviroment variables\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set API keys and secret\n",
    "alpaca_api_key = os.getenv(\"ALPACA_API_KEY\")\n",
    "alpaca_secret_key = os.getenv(\"ALPACA_SECRET_KEY\")\n",
    "quandl_api_key = os.getenv(\"QUANDL_API_KEY\")\n",
    "rapid_api_key = os.getenv(\"RAPID_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set file path and import all .yaml files into Pandas DataFrame\n",
    "path = r\"C:\\Users\\berny\\Desktop\\Fintechbootcamp\\HUMAN ROBOT\\BC_Project_1\\BC_Project_1\"\n",
    "all_files = glob.glob(path + \"/*.yaml\")\n",
    "li = []\n",
    "for filename in all_files[:10]:\n",
    "    with open(filename, \"r\") as fh:\n",
    "        df = pd.json_normalize(yaml.safe_load(fh.read()))\n",
    "    li.append(df)\n",
    "all_cust_kyc = pd.concat(li)\n",
    "columns = [\"Date\", \"First Name\", \"Last Name\", \"Birth Date\", \"Annual Income\", \"Initial Investment\", \"Occupation\", \"Investment Goals\", \"Investment Time Horizon\", \"Risk Tolerance\", \"Investment Constraints\"]\n",
    "all_cust_kyc.columns = columns\n",
    "all_cust_kyc = all_cust_kyc.set_index(all_cust_kyc[\"Last Name\"])\n",
    "\n",
    "all_cust_kyc = all_cust_kyc.sort_index()\n",
    "all_cust_kyc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access Columns in Dataframe\n",
    "risk = all_cust_kyc[\"Risk Tolerance\"]\n",
    "income = all_cust_kyc[\"Annual Income\"]\n",
    "goals = all_cust_kyc[\"Investment Goals\"]\n",
    "horizon = all_cust_kyc[\"Investment Time Horizon\"]\n",
    "initial_investment = all_cust_kyc[\"Initial Investment\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set customer last name\n",
    "customer = \"Sher\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through data given content of 'customer'\n",
    "cust = all_cust_kyc[\"Last Name\"]\n",
    "\n",
    "for name in cust:\n",
    "    if customer == cust[0]:\n",
    "        r = risk[0] \n",
    "        i = income[0]\n",
    "        g = goals[0]\n",
    "        h = horizon[0]\n",
    "    elif customer == cust[1]:\n",
    "        r = risk[1] \n",
    "        i = income[1]\n",
    "        g = goals[1]\n",
    "        h = horizon[1]\n",
    "    elif customer == cust[2]:\n",
    "        r = risk[2] \n",
    "        i = income[2]\n",
    "        g = goals[2]\n",
    "        h = horizon[2]\n",
    "    elif customer == cust[3]:\n",
    "        r = risk[3] \n",
    "        i = income[3]\n",
    "        g = goals[3]\n",
    "        h = horizon[3]\n",
    "    elif customer == cust[4]:\n",
    "        r = risk[4] \n",
    "        i = income[4]\n",
    "        g = goals[4]\n",
    "        h = horizon[4]\n",
    "    \n",
    "print(f\"{customer}: r = {r}, i = {i}, g = {g}, h = {h}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Categorize client's by assigning numerical value to Risk Tolerance (r)/ Annual Income (i) / Investment Goals (g)/ Time Horizon (h) \n",
    "if r == \"low\":\n",
    "    assign_r = 0\n",
    "elif r == \"medium\":\n",
    "    assign_r = 1\n",
    "elif r == \"high\":\n",
    "    assign_r = 2\n",
    "\n",
    "if i <= 75000:\n",
    "    assign_i = 0\n",
    "elif i >= 75001 and income <= 150000:\n",
    "    assign_i = 1\n",
    "elif i >= 150001:\n",
    "    assign_i = 2\n",
    "\n",
    "## Categorize client's Investment Goals\n",
    "if g == \"preservation\":\n",
    "    assign_g = 0\n",
    "elif g == \"income\":\n",
    "    assign_g = 1\n",
    "elif g == \"growth\":\n",
    "    assign_g = 2\n",
    "    \n",
    "if h >= 0 and h <= 10:\n",
    "    assign_h = 3\n",
    "elif h >= 11 and h <= 20:\n",
    "    assign_h = 2\n",
    "elif h >= 21:\n",
    "    assign_h = 1\n",
    "    \n",
    "print(f\"{customer}: r = {r}, i = {i}, g = {g}, h = {h}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compile client categorizations to determine portfolio suitability\n",
    "pn = assign_r + assign_i + assign_g + assign_h\n",
    "if pn >= 0 and pn <= 2.5:\n",
    "    assign_portfolio = 1\n",
    "if pn >= 3 and pn <= 5:\n",
    "    assign_portfolio = 2\n",
    "if pn >= 5.5: \n",
    "    assign_portfolio = 3\n",
    "print(f\"{customer} Portfolio Number is {pn}, assign {customer} to Portfolio {assign_portfolio}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine portfolio assignment outcome for subsequent analysis \n",
    "if pn == 1:\n",
    "    portfolio = portfolio_1\n",
    "elif pn == 2:\n",
    "    portfolio = portfolio_2\n",
    "elif pn == 3:\n",
    "    portfolio = portfolio_3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Import and Clean Stock Data for Fundamental and Statistical Analysis\n",
    "##### Our company has selected top performing stocks from the S&P 500 Index as our core portfolio. For these companies, we import important fundamental data garnered from the companies' balance sheets. Although we have not yet fully integrated this information into our analysis, we include this data now because proper due diligence will eventually require performing fundamental ratio analysis that will give us a better portrait of the overall performance of these companies, and also of their performance compared to market, sector, and industry peers and competitors. For now we have limited our fundamental analysis to Price-Earnings (P/E) Ratios. Our stock selections comes as a result of many years of analysis, market research, and market participation. Our core portfolio selection is composed of stocks in which we have been invested for more than 20 years, hence our choice of 20 years of historical performance data. Along the way, we have added 'SHOP', 'PYPL', and 'DAL', as they have fit our rigorous criteria for adoption. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set timeframe (YYYY-MM-DD)\n",
    "start_date = '2000-01-01'\n",
    "today = date.today()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Ticker list\n",
    "ticker_list = ['SPY','AAPL','AMZN','DAL','GE','JNJ','MSFT','MNST','PYPL','SHOP','UPS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function that grabs a Yahoo Finance JSON URL and outputs the results as a dictionary\n",
    "#Code Ref: https://marqueegroup.ca/resource/how-to-use-python-in-a-finance-environment/\n",
    "\n",
    "def fnYFinJSON(stock):\n",
    "  urlData = \"https://query2.finance.yahoo.com/v7/finance/quote?symbols=\"+stock\n",
    "  webUrl = urllib.request.urlopen(urlData)\n",
    "  if (webUrl.getcode() == 200):\n",
    "    data = webUrl.read()\n",
    "  else:\n",
    "      print (\"Received an error from server, cannot retrieve results \" + str(webUrl.getcode()))\n",
    "  yFinJSON = json.loads(data)\n",
    "  return yFinJSON[\"quoteResponse\"][\"result\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a table based on tickers and company info fields needed\n",
    "tickers = ticker_list\n",
    "fields = {'shortName':'Company Name',  \n",
    "          'fullExchangeName':'Exchange', \n",
    "          'marketCap':'Market Cap',\n",
    "          'regularMarketPrice':'Price',\n",
    "          'fiftyTwoWeekLow':'52-Wk Low', \n",
    "          'fiftyTwoWeekHigh':'52-Wk High',\n",
    "          'regularMarketDayHigh':'High', \n",
    "          'regularMarketDayLow':'Low',\n",
    "          'regularMarketVolume': 'Volume',\n",
    "          'averageDailyVolume3Month': 'Ave. Quarterly Vol.',\n",
    "          'epsTrailingTwelveMonths':'EPS(TTM)',\n",
    "          'trailingPE': 'PE Ratio (TTM)'\n",
    "         }\n",
    "results = {}\n",
    "for ticker in tickers:\n",
    "  tickerData = fnYFinJSON(ticker)\n",
    "  singleResult = {}\n",
    "  for key in fields.keys():\n",
    "    if key in tickerData:\n",
    "      singleResult[fields[key]] = tickerData[key]\n",
    "    else:\n",
    "      singleResult[fields[key]] = \"N/A\"\n",
    "  results[ticker] = singleResult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arrange index according to a specific order\n",
    "# Code Ref:https://stackoverflow.com/questions/55397178/dataframe-creation-from-dict-index-order\n",
    "\n",
    "co_info_label = ['Company Name', \n",
    "                 'Exchange', \n",
    "                 'Market Cap',\n",
    "                 'Price',\n",
    "                 'Low',\n",
    "                 'High', \n",
    "                 '52-Wk Low', \n",
    "                 '52-Wk High',\n",
    "                 'Volume',\n",
    "                 'Ave. Quarterly Vol.',\n",
    "                 'EPS(TTM)',\n",
    "                 'PE Ratio (TTM)',\n",
    "                ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "company_info_df = pd.DataFrame.from_dict(results)\n",
    "company_info_df = company_info_df.reindex(co_info_label)\n",
    "company_info_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YahooFinancials - Revenue \n",
    "yahoo_financials_tickers = YahooFinancials(ticker_list)\n",
    "earnings = yahoo_financials_tickers.get_stock_earnings_data(reformat=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Import and Cleaning Data for PE Ratios:\n",
    "##### To acquire results of companies history of PE Ratios to determine the strenth of the stock."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import csv data for \n",
    "AAPL_PE_path  = Path(\"AAPL Comparison-to-Industry.csv\")\n",
    "all_historical_PE_path = Path(\"all_stocks_historical_PE_ratio.csv\")  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read dataframe\n",
    "AAPL_PE_df  = pd.read_csv(AAPL_PE_path, parse_dates=True, infer_datetime_format=True)\n",
    "AAPL_PE_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#display colomns name\n",
    "AAPL_PE_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change colomns name\n",
    "columns = [\"Date\", \"Apple Inc.\", \"Technology\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dispaly new colomns name\n",
    "AAPL_PE_df.columns = columns\n",
    "AAPL_PE_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#display table from row 3 to the end\n",
    "AAPL_PE_df = AAPL_PE_df[3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read dataframe\n",
    "AAPL_PE_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change datatype frome object to datetime64[ns]\n",
    "AAPL_PE_df['Date'] = AAPL_PE_df['Date'].astype('datetime64[ns]')\n",
    "AAPL_PE_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change datatype from object to float64\n",
    "AAPL_PE_df['Apple Inc.'] = AAPL_PE_df['Apple Inc.'].astype('float')\n",
    "AAPL_PE_df['Technology'] = AAPL_PE_df['Technology'].astype('float')\n",
    "AAPL_PE_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set \"Date\" as index\n",
    "AAPL_PE_df = AAPL_PE_df.set_index(AAPL_PE_df[\"Date\"])\n",
    "AAPL_PE_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#delete \"date\" columne\n",
    "AAPL_PE_df = AAPL_PE_df.drop(columns=[\"Date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sort date\n",
    "AAPL_PE_df.sort_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#display data frame\n",
    "AAPL_PE_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot data frame\n",
    "AAPL_PE=AAPL_PE_df.hvplot(\n",
    "                width=750, height=450,rot=45,\n",
    "                title=\"Apple Inc., P/E, long-term trends, comparison to industry (technology)\")\n",
    "AAPL_PE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read dataframe\n",
    "all_historical_PE_df  = pd.read_csv(all_historical_PE_path, parse_dates=True, infer_datetime_format=True)\n",
    "all_historical_PE_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#delete columne \"Date\"\n",
    "all_historical_PE_df = all_historical_PE_df.drop(columns=[\"Date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sort index\n",
    "all_historical_PE_df.sort_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_historical_PE_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename columns\n",
    "columns = [\"AAPL\",\"AMZN\",\"DAL\",\"GE\",\"JNJ\",\"MSFT\",\"MNST\",\"PYPL\",\"SHOP\",\"UPS\",\"SPY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set new columns name\n",
    "all_historical_PE_df.columns = columns\n",
    "all_historical_PE_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change 'SPY' data from object to float\n",
    "all_historical_PE_df['SPY'] = all_historical_PE_df['SPY'].astype('float')\n",
    "all_historical_PE_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot dataframe\n",
    "historical_PE = all_historical_PE_df.hvplot(\n",
    "                y = ['AAPL', \"AMZN\",'DAL', 'GE', 'JNJ',\"MSFT\",\"MNST\",\"PYPL\",\"SHOP\",\"UPS\",\"SPY\"],\n",
    "                width=950, height=450,rot=90,\n",
    "                title=\"P/E, long-term trends, comparison to S&P 500\")  \n",
    "historical_PE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Conduct Statistical Analysis on Historical Stock Data to Allocate Stocks to Portfolios\n",
    "##### We conduct statistical analysis on our stock data with the intention of using these numbers to organize our stocks into their respective portfolio designations to suit the categories into which we have organized our portfolio offerings. The three criteria we have chosen for allocating stocks to these respective portfolios are annualized  Standard Deviation, Cumulative Retunrs, Cumulative Risk, Beta ,and Sharpe Ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download historical statistical data = 20 years\n",
    "## Import Stock Data\n",
    "stat_data_20yr = yf.download(\"SPY AAPL AMZN DAL GE JNJ MSFT MNST PYPL SHOP UPS\", start=\"2000-01-01\", end=today).Close\n",
    "stat_data_20yr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code Ref: https://stackoverflow.com/questions/38133064/get-adj-close-using-pandas-datareader\n",
    "stocks_adjclose_20yr = yf.download(ticker_list,  start='2000-01-01', end = today, period = \"1d\")['Adj Close']\n",
    "stocks_adjclose_20yr = stocks_adjclose_20yr.fillna(0)\n",
    "stocks_adjclose_20yr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate daily returns\n",
    "daily_returns_20yr = stocks_adjclose_20yr.pct_change()\n",
    "daily_returns_20yr = daily_returns_20yr.fillna(0)\n",
    "daily_returns_20yr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculate the standard deviation\n",
    "daily_returns_20yr_std = daily_returns_20yr.std()\n",
    "daily_returns_20yr_std = daily_returns_20yr_std.sort_values()\n",
    "daily_returns_20yr_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average Daily Returns\n",
    "daily_returns_20yr_mean = daily_returns_20yr.mean().round(5)\n",
    "print(daily_returns_20yr_mean)\n",
    "daily_returns_20yr_mean.head().round(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculate the annualized standard deviation\n",
    "ann_portfolio_std = daily_returns_20yr_std * np.sqrt(252)\n",
    "ann_portfolio_std = ann_portfolio_std.sort_values()\n",
    "ann_portfolio_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate cumulative returns of all portfolios\n",
    "cumulative_returns = (1+daily_returns_20yr).cumprod() -1\n",
    "cumulative_returns.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cumulative_std = cumulative_returns.std()\n",
    "print(cumulative_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine which portfolios are riskier than the S&P 500\n",
    "cumulative_risk = cumulative_std[cumulative_std > cumulative_std[\"SPY\"]]\n",
    "print(cumulative_risk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the annualized standard deviation (252 trading days)\n",
    "annual_std = cumulative_std * np.sqrt(252)\n",
    "annual_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sharpe_ratios = (cumulative_returns.mean() * 252) / (cumulative_returns.std() * np.sqrt(252))\n",
    "sharpe_ratios.sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### We have now compiled our stock information sufficiently to be able to allocate these stocks to our respective portfolios. Below we define our specific portfolios and begin analysis on them so that we will be able to provide our client with sufficient information and visualizations that they can be confident they have had an appropriate portfolio selected for them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### We need code to extract the P/E Ratios, sharpe ratios, and annualized standard deviation for each data set. \n",
    "# if sharpe_ratio <= . . . etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "portfolio_1 = stocks.drop(columns=[\"SPY\", \"SHOP\", \"DAL\", \"GE\", \"PYPL\"]) \n",
    "portfolio_2 = stocks.drop(columns=[\"SPY\", \"JNJ\", \"UPS\", \"SHOP\", \"DAL\"])\n",
    "portfolio_3 = stocks.drop(columns=[\"SPY\", \"JNJ\", \"UPS\", \"MSFT\", \"MNST\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Portfolio return, volatility, Sharpe Ratio\n",
    "\n",
    "annualized_return = ((np.mean(portfolio['Total'].pct_change() + 1)) ** 252 - 1)\n",
    "\n",
    "annualized_vol = np.std(portfolio['Total'].pct_change()) * np.sqrt(252)\n",
    "\n",
    "Sharpe_Ratio = (annualized_return - 0.025) / annualized_vol  # 2.5% risk-free rate\n",
    "\n",
    "print('Our portfolio delivered a', \"{0:.1%}\".format(annualized_return), \n",
    "      'annual return, with a', \"{0:.1%}\".format(annualized_vol), \n",
    "      'volatility rate, resulting in a Sharpe Ratio of', \"{0:.2f}\".format(Sharpe_Ratio))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5) Perform Monte Carlo Simulation to Predict the Profitability for Client's Portfolio According to Investment Time Horizon\n",
    "##### We are in the process of determining another way to get a baseline dataframe arranged that allows us to conduct a Monte Carlo analysis without being limited by the alpaca API's 1000 object limit per call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Alpaca API key and secret\n",
    "alpaca_api_key = os.getenv(\"ALPACA_API_KEY\")\n",
    "alpaca_secret_key = os.getenv(\"ALPACA_SECRET_KEY\")\n",
    "\n",
    "# Create the Alpaca API object\n",
    "alpaca = tradeapi.REST(\n",
    "    alpaca_api_key,\n",
    "    alpaca_secret_key,\n",
    "    base_url=\"https://paper-api.alpaca.markets\",\n",
    "    api_version=\"v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format current date as ISO format\n",
    "\n",
    "today = pd.Timestamp(\"2021-04-09\", tz=\"America/New_York\").isoformat() \n",
    "\n",
    "\n",
    "# Set the tickers\n",
    "tickers = [\"SPY\",\"AGG\"]\n",
    "\n",
    "# Set timeframe to '1D' for Alpaca API\n",
    "timeframe = \"1D\"\n",
    "\n",
    "# Get current closing prices for SPY and AGG\n",
    "\n",
    "df_portfolio = alpaca.get_barset(\n",
    "    tickers,\n",
    "    timeframe,\n",
    "    start = today,\n",
    "    end = today\n",
    ").df\n",
    "\n",
    "\n",
    "# Preview DataFrame\n",
    "df_portfolio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set start and end dates of five years back from today.\n",
    "# Sample results may vary from the solution based on the time frame chosen\n",
    "start_date = pd.Timestamp('2000-01-01', tz='America/New_York').isoformat()\n",
    "end_date = pd.Timestamp('today', tz='America/New_York').isoformat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get 5 years' worth of historical data for SPY and AGG\n",
    "df_stock_data = alpaca.get_barset(\n",
    "    tickers,\n",
    "    timeframe,\n",
    "    start=start_date,\n",
    "    end=end_date,limit=1000\n",
    ").df\n",
    "\n",
    "\n",
    "# Display sample data\n",
    "df_stock_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuring a Monte Carlo simulation to forecast 20 years cumulative returns\n",
    "MC_20_yrs = MCSimulation(\n",
    "    portfolio_data = df_stock_data,\n",
    "    num_simulation = 500,\n",
    "    num_trading_days = 252*20\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing the simulation input data\n",
    "MC_20_yrs.portfolio_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running a Monte Carlo simulation to forecast 20 years cumulative returns\n",
    "MC_20_yrs.calc_cumulative_return()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot simulation outcomes\n",
    "line_plot = MC_20_yrs.plot_simulation()\n",
    "\n",
    "# Save the plot for future usage\n",
    "line_plot.get_figure().savefig(\"MC_20_yr_sim_plot.png\", bbox_inches=\"tight\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot probability distribution and confidence intervals\n",
    "dist_plot = MC_20_yrs.plot_distribution()\n",
    "#dist_chart = dist_plot.hvplot(title='Distribution of Final Cumulative Returns Across All 500 Simulations', height = 450, width = 750)\n",
    "#dist_chart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6) Visualizations, Panel, and Customer Dashboard\n",
    "##### Our HumanRobo now compile representations of our analysis to provide the client with an interactive dashboard by which they can see the analytics of their respective portfolio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_data_20yr.hvplot.line(title='All Stocks Closing Prices in 20 years',height = 450, width = 900)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#daily_returns_20yr.plot(figsize = (20, 10))\n",
    "#plt.title('Daily Returns')\n",
    "#plt.ylabel('Percent')\n",
    "daily_returns_20yr_plot = daily_returns_20yr.hvplot.line(title='All Stocks 20 years Daily Returns',height = 450, width = 900)\n",
    "daily_returns_20yr_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#daily_returns_20yr_mean.sort_values().plot(figsize = (20, 10))\n",
    "#plt.title('Average Daily Returns')\n",
    "#plt.xlabel('Percent')\n",
    "daily_returns_20yr_mean.hvplot.bar(title='All Stocks 20 Years Average Daily Returns',height = 450, width = 750)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_returns_correlation = daily_returns_20yr.corr()\n",
    "#fig = plt.figure(figsize=(15,10))\n",
    "#sns.heatmap(daily_returns_correlation, vmin=-1, vmax=1)\n",
    "daily_returns_correlation.hvplot(kind='heatmap',title='All Stocks 20 Years Daily Returns Correlation', height = 450, width = 750)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box plot to visually show risk\n",
    "#cumulative_returns.plot.box(figsize=(20,10))\n",
    "\n",
    "#plt.title(\"cumulative returns in form of a box presentation of all the funds and SPY\")\n",
    "#plt.ylim(-100, 1150)\n",
    "#plt.show()\n",
    "\n",
    "\n",
    "boxplot = cumulative_returns.hvplot.box(title='Box Plot', height = 450, width = 750, legend=False)\n",
    "boxplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot dataframe\n",
    "historical_PE = all_historical_PE_df.hvplot(\n",
    "                y = ['AAPL', \"AMZN\",'DAL', 'GE', 'JNJ',\"MSFT\",\"MNST\",\"PYPL\",\"SHOP\",\"UPS\",\"SPY\"],\n",
    "                width=950, height=450,rot=90,\n",
    "                title=\"P/E, long-term trends, comparison to S&P 500\")  \n",
    "historical_PE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot cumulative returns\n",
    "#cumulative_returns.plot(figsize=(20,10))\n",
    "#plt.title(\"Daily returns of all the funds, stocks and EFTs\")\n",
    "cumulative_returns.hvplot.line(title='20 years Cumulative Daily Returns of all Stocks', height = 450, width = 750)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the correlation\n",
    "correlation = cumulative_returns.corr()\n",
    "# Display de correlation matrix\n",
    "#sns.heatmap(correlation, vmin=-3, vmax=3, annot=True)\n",
    "#correlation\n",
    "#plt.title(\"Heat map of correlation for all the funds and SPY\")\n",
    "correlation.hvplot(kind='heatmap',title=\"Heat Map of Correlation for all Stocks and SPY\", height = 450, width = 750)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the main dashboard\n",
    "dashboard2  = pn.Tabs(\n",
    "            (\"Daily Returns\", daily_returns_20yr_plot),\n",
    "            (\"Sharpe Ratios\",sharpe_ratios),            \n",
    ")\n",
    "dashboard2.servable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the main dashboard\n",
    "dashboard3 = pn.Tabs(\n",
    "           (\"AAPL PE Ratio\",AAPL_PE))\n",
    "\n",
    "dashboard3.servable()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison of investment of $2000 vs $200,000\n",
    "### Write here "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pyvizenv] *",
   "language": "python",
   "name": "conda-env-pyvizenv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
